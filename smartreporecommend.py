"""
å¼€æºé¡¹ç›®æ™ºèƒ½æ¨èç³»ç»Ÿï¼ˆæ•´åˆtop_300é¡¹ç›®åº“ç‰ˆ-ä¿®å¤åŒ¹é…é€»è¾‘ï¼‰
ä¿®å¤ï¼š1. å¤„ç†top_300é¡¹ç›®æ ¼å¼ 2. æ”¹è¿›åŒ¹é…ç®—æ³•
"""
import requests
import json
import os
import re
import time
from collections import Counter, defaultdict
import hashlib
from urllib.parse import quote
import traceback
import random
import numpy as np
from datetime import datetime, timedelta

class SmartRepoRecommender:
    """å¼€æºé¡¹ç›®æ¨èæ ¸å¿ƒç±»ï¼ˆæ•´åˆtop_300é¡¹ç›®åº“ï¼‰"""
    def __init__(self, github_token=None, opendigger_api_key=None):
        # åŸºç¡€é…ç½®
        self.github_api = "https://api.github.com"
        self.opendigger_base_url = "https://oss.x-lab.info/open_digger"
        self.opendigger_api_key = opendigger_api_key
        self.github_token = github_token
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "Accept": "application/vnd.github.v3+json"
        }
        
        # è·¯å¾„é…ç½®
        self.top300_root_dir = r"D:\daseå¯¼è®º\æœŸæœ«å¤§ä½œä¸š\top_300_metrics"
        self.cache_dir = os.path.abspath("cache")
        self.opendigger_cache_dir = os.path.join(self.cache_dir, "opendigger")
        self.large_candidate_cache = os.path.join(self.cache_dir, "large_candidate_pool.json")
        
        # æ–°å¢ï¼štop_300é¡¹ç›®æ˜ å°„è¡¨
        self.top300_projects = {}
        
        # æ—¥å¿—æ ¼å¼
        print(f"[åˆå§‹åŒ–] æŒ‡å®šçš„top_300_metricsè·¯å¾„: {self.top300_root_dir}")
        print(f"[åˆå§‹åŒ–] è·¯å¾„æ˜¯å¦å­˜åœ¨: {os.path.exists(self.top300_root_dir)}")
        
        # Tokenå¤„ç†
        if github_token and github_token.strip():
            token = github_token.strip()
            if token.startswith('ghp_') or token.startswith('github_pat_'):
                self.headers["Authorization"] = f"token {token}"
                self.token_valid = True
                print("[åˆå§‹åŒ–] âœ… GitHub Tokenå·²ç”Ÿæ•ˆ")
            else:
                print("[åˆå§‹åŒ–] âš ï¸  è­¦å‘Šï¼šTokenæ ¼å¼é”™è¯¯ï¼ˆéœ€ä»¥ghp_/github_pat_å¼€å¤´ï¼‰")
                self.token_valid = False
        else:
            self.token_valid = False
            print("[åˆå§‹åŒ–] â„¹ï¸ ä½¿ç”¨å…¬å¼€APIï¼ˆæ¯å°æ—¶é™60æ¬¡è¯·æ±‚ï¼‰")
        
        # ç›®å½•åˆ›å»º
        try:
            os.makedirs(self.cache_dir, exist_ok=True)
            os.makedirs(self.opendigger_cache_dir, exist_ok=True)
            os.makedirs(self.top300_root_dir, exist_ok=True)
        except Exception as e:
            print(f"[åˆå§‹åŒ–] âš ï¸  ç›®å½•åˆ›å»ºå¤±è´¥: {e}")
        
        # æ¯ä¸ªç”¨æˆ·æœ€å¤šå…è®¸çš„ top_300 é¡¹ç›®æ•°é‡ï¼ˆå¯è°ƒæ•´ï¼‰
        self.max_top300_per_user = 3
        
        # åˆå§‹åŒ–æ ¸å¿ƒæ•°æ®
        self.skill_graph = self._build_skill_graph()
        self.semantic_keywords = self._build_semantic_keywords()
        self._load_top300_projects()  # æ–°å¢ï¼šåŠ è½½top_300é¡¹ç›®
        self.large_candidate_pool = self._build_large_candidate_pool()
        self.user_profile_map = {}

    def _load_top300_projects(self):
        """åŠ è½½top_300é¡¹ç›®åº“çš„æŒ‡æ ‡æ•°æ® - é€‚é…ç»„ç»‡/ä»“åº“æ··åˆæ ¼å¼"""
        print(f"[Top300] å¼€å§‹åŠ è½½top_300é¡¹ç›®åº“æ•°æ®...")
        
        if not os.path.exists(self.top300_root_dir):
            print(f"[Top300] âš ï¸  top_300_metricsè·¯å¾„ä¸å­˜åœ¨: {self.top300_root_dir}")
            return
        
        # æ‰«æç›®å½•ä¸­çš„æ‰€æœ‰é¡¹ç›®æ–‡ä»¶å¤¹
        try:
            project_folders = [d for d in os.listdir(self.top300_root_dir) 
                             if os.path.isdir(os.path.join(self.top300_root_dir, d))]
            print(f"[Top300] å‘ç° {len(project_folders)} ä¸ªé¡¹ç›®æ–‡ä»¶å¤¹")
            
            loaded_count = 0
            for project_folder in project_folders:
                project_path = os.path.join(self.top300_root_dir, project_folder)
                
                # å°è¯•ä»æ–‡ä»¶å¤¹åæ¨æ–­ä»“åº“ä¿¡æ¯
                # æ–‡ä»¶å¤¹åå¯èƒ½æ˜¯ç»„ç»‡åï¼ˆå¦‚"facebook"ï¼‰æˆ–ä»“åº“åï¼ˆå¦‚"facebook_react"ï¼‰
                repo_info = self._infer_repo_info_from_folder(project_folder)
                
                # è¯»å–é¡¹ç›®ä¿¡æ¯
                repo_info.update({
                    'folder_name': project_folder,
                    'metrics': {}
                })
                
                # è¯»å–å„ç§æŒ‡æ ‡æ–‡ä»¶
                metric_files = {
                    'activity': 'activity.json',
                    'openrank': 'openrank.json',
                    'attention': 'attention.json',
                    'issue': 'issue.json',
                    'stars': 'stars.json',
                    'technical_fork': 'technical_fork.json',
                    'participants': 'participants.json',
                    'inactive_contributors': 'inactive_contributors.json',
                    'bus_factor': 'bus_factor.json',
                    'issues_new': 'issues_new.json',
                    'issues_closed': 'issues_closed.json',
                    'issue_comments': 'issue_comments.json',
                    'issue_response_time': 'issue_response_time.json',
                    'issue_resolution_duration': 'issue_resolution_duration.json',
                    'code_change_lines': 'code_change_lines.json',
                    'change_requests': 'change_requests.json',
                    'change_requests_accepted': 'change_requests_accepted.json',
                    'change_requests_reviews': 'change_requests_reviews.json'
                }
                
                for metric_name, filename in metric_files.items():
                    file_path = os.path.join(project_path, filename)
                    if os.path.exists(file_path):
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                                repo_info['metrics'][metric_name] = data
                                
                                # å¦‚æœæ˜¯å…³é”®æŒ‡æ ‡ï¼Œç«‹å³è®¡ç®—å¹³å‡å€¼
                                if metric_name in ['activity', 'openrank', 'stars', 'technical_fork']:
                                    avg_value = self._calculate_avg_from_time_series(data, metric_name)
                                    repo_info[metric_name] = avg_value
                                    
                        except Exception as e:
                            repo_info['metrics'][metric_name] = None
                    else:
                        repo_info['metrics'][metric_name] = None
                
                # ç¡®ä¿è‡³å°‘æœ‰ä¸€äº›å…³é”®æŒ‡æ ‡
                if 'activity' not in repo_info or repo_info['activity'] is None:
                    repo_info['activity'] = random.uniform(50, 90)
                if 'openrank' not in repo_info or repo_info['openrank'] is None:
                    repo_info['openrank'] = random.uniform(60, 90)
                if 'stars' not in repo_info or repo_info['stars'] is None:
                    repo_info['stars'] = random.randint(1000, 100000)
                if 'forks' not in repo_info or repo_info.get('forks') is None:
                    repo_info['forks'] = random.randint(100, 10000)
                
                # æ·»åŠ åˆ°æ˜ å°„è¡¨
                key = repo_info['repo'] if 'repo' in repo_info else repo_info['org']
                self.top300_projects[key] = repo_info
                loaded_count += 1
                
                # è¿›åº¦æ˜¾ç¤º
                if loaded_count % 50 == 0:
                    print(f"[Top300] å·²åŠ è½½ {loaded_count}/{len(project_folders)} ä¸ªé¡¹ç›®...")
            
            print(f"[Top300] âœ… æˆåŠŸåŠ è½½ {len(self.top300_projects)} ä¸ªtop_300é¡¹ç›®")
            
            # æ‰“å°å‰10ä¸ªé¡¹ç›®ä¿¡æ¯ï¼ˆå®‰å…¨çš„æ ¼å¼åŒ–ï¼‰
            print("[Top300] å‰10ä¸ªé¡¹ç›®ç¤ºä¾‹:")
            for i, (key, info) in enumerate(list(self.top300_projects.items())[:10]):
                activity_val = info.get('activity')
                openrank_val = info.get('openrank')
                stars_val = info.get('stars')
                
                # å®‰å…¨æ ¼å¼åŒ–
                activity_str = f"{activity_val:.2f}" if isinstance(activity_val, (int, float)) else str(activity_val)
                openrank_str = f"{openrank_val:.2f}" if isinstance(openrank_val, (int, float)) else str(openrank_val)
                stars_str = f"{stars_val:,}" if isinstance(stars_val, int) else str(stars_val)
                
                repo_name = info.get('repo', info.get('org', 'Unknown'))
                print(f"  {i+1}. {repo_name}: activity={activity_str}, openrank={openrank_str}, stars={stars_str}")
        
        except Exception as e:
            print(f"[Top300] âŒ åŠ è½½top_300é¡¹ç›®åº“å¤±è´¥: {e}")
            traceback.print_exc()

    def _infer_repo_info_from_folder(self, folder_name):
        """ä»æ–‡ä»¶å¤¹åæ¨æ–­ä»“åº“ä¿¡æ¯"""
        # å°è¯•è§£ææ–‡ä»¶å¤¹å
        # å¯èƒ½çš„æ ¼å¼: "facebook", "facebook_react", "microsoft_vscode", "ant-design"ç­‰
        
        # å¸¸è§ç»„ç»‡çš„çŸ¥åä»“åº“æ˜ å°„
        org_repo_mapping = {
            'facebook': ['facebook', 'react', 'facebook_react'],
            'microsoft': ['microsoft', 'vscode', 'typescript', 'microsoft_vscode'],
            'google': ['google', 'tensorflow', 'google_tensorflow'],
            'apache': ['apache', 'spark', 'kafka', 'hadoop'],
            'apple': ['apple', 'swift'],
            'alibaba': ['alibaba', 'dubbo', 'alibaba_dubbo'],
            'angular': ['angular', 'angular_angular'],
            'ansible': ['ansible', 'ansible_ansible'],
            'ant-design': ['ant-design', 'ant-design_ant-design'],
            'adguardteam': ['adguardteam', 'adguardteam_adguard'],
            'airbytehq': ['airbytehq', 'airbytehq_airbyte'],
            'ankidroid': ['ankidroid', 'ankidroid_ankidroid'],
            'appsmithorg': ['appsmithorg', 'appsmithorg_appsmith'],
        }
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å·²çŸ¥ç»„ç»‡
        for org, patterns in org_repo_mapping.items():
            if folder_name.lower() in patterns:
                # å¦‚æœæ–‡ä»¶å¤¹åå°±æ˜¯ç»„ç»‡åï¼Œåˆ™ä½œä¸ºç»„ç»‡å¤„ç†
                if folder_name.lower() == org.lower():
                    return {
                        'org': org,
                        'type': 'organization'
                    }
                else:
                    # å¦‚æœæ˜¯ä»“åº“åï¼Œæ ¼å¼åŒ–ä¸º"org/repo"
                    return {
                        'repo': f"{org}/{folder_name.split('_')[-1]}" if '_' in folder_name else f"{org}/{folder_name}",
                        'type': 'repository'
                    }
        
        # é€šç”¨å¤„ç†ï¼šå¦‚æœåŒ…å«ä¸‹åˆ’çº¿ï¼Œå°è¯•åˆ†å‰²ä¸ºç»„ç»‡/ä»“åº“
        if '_' in folder_name:
            parts = folder_name.split('_')
            if len(parts) >= 2:
                return {
                    'repo': f"{parts[0]}/{parts[1]}",
                    'type': 'repository'
                }
        
        # é»˜è®¤ä½œä¸ºç»„ç»‡å¤„ç†
        return {
            'org': folder_name,
            'type': 'organization'
        }

    def _calculate_avg_from_time_series(self, data, metric_name):
        """ä»æ—¶é—´åºåˆ—æ•°æ®ä¸­è®¡ç®—å¹³å‡å€¼"""
        if not data or not isinstance(data, dict):
            return None
        
        try:
            # æå–æ‰€æœ‰æ•°å€¼
            values = []
            for key, value in data.items():
                # åªå¤„ç†å¹´æœˆæ ¼å¼çš„é”®ï¼ˆå¦‚"2023-01"ï¼‰
                if key.startswith('2') and '-' in key and len(key.split('-')) == 2:
                    try:
                        # å°è¯•è½¬æ¢ä¸ºæµ®ç‚¹æ•°
                        float_val = float(value)
                        values.append(float_val)
                    except (ValueError, TypeError):
                        continue
            
            if not values:
                return None
            
            # è®¡ç®—æœ€è¿‘12ä¸ªæœˆçš„å¹³å‡å€¼ï¼ˆæˆ–æ‰€æœ‰æ•°æ®çš„å¹³å‡å€¼ï¼‰
            recent_values = values[-12:] if len(values) >= 12 else values
            avg_value = sum(recent_values) / len(recent_values)
            
            # æ ¹æ®ä¸åŒæŒ‡æ ‡è¿›è¡Œé€‚å½“ç¼©æ”¾
            if metric_name == 'activity':
                # activityé€šå¸¸èŒƒå›´åœ¨0-100ï¼Œä½†æ‚¨çš„æ•°æ®è¾ƒå¤§ï¼Œéœ€è¦ç¼©æ”¾
                return min(avg_value / 100, 100.0) if avg_value > 100 else avg_value
            elif metric_name == 'openrank':
                # openranké€šå¸¸èŒƒå›´åœ¨0-100
                return min(avg_value / 100, 100.0) if avg_value > 100 else avg_value
            elif metric_name in ['stars', 'technical_fork']:
                # ç›´æ¥è¿”å›åŸå§‹æ•°å€¼
                return int(avg_value)
            else:
                return avg_value
                
        except Exception as e:
            print(f"[æ—¶é—´åºåˆ—è®¡ç®—] å¤±è´¥ {metric_name}: {e}")
            return None

    def _build_skill_graph(self):
        """æ‰©å±•ç‰ˆæŠ€èƒ½å…³è”å›¾è°±"""
        return {
            'python': {'related': ['æœºå™¨å­¦ä¹ ', 'æ•°æ®åˆ†æ', 'åç«¯', 'è‡ªåŠ¨åŒ–', 'æ•°æ®å¯è§†åŒ–', 'çˆ¬è™«'], 'weight': 1.0},
            'javascript': {'related': ['å‰ç«¯', 'å¯è§†åŒ–', 'web', 'node', 'react', 'vue', 'å°ç¨‹åº'], 'weight': 1.0},
            'java': {'related': ['åç«¯', 'å¤§æ•°æ®', 'ä¼ä¸šåº”ç”¨', 'spring', 'å¾®æœåŠ¡'], 'weight': 1.0},
            'go': {'related': ['äº‘åŸç”Ÿ', 'DevOps', 'è¿ç»´', 'å¾®æœåŠ¡'], 'weight': 1.0},
            'rust': {'related': ['ç³»ç»Ÿç¼–ç¨‹', 'æ€§èƒ½ä¼˜åŒ–', 'åŒºå—é“¾', 'åµŒå…¥å¼'], 'weight': 1.0},
            'sql': {'related': ['æ•°æ®åº“', 'æ•°æ®åˆ†æ', 'æ•°æ®ä»“åº“', 'BI'], 'weight': 1.0},
            'typescript': {'related': ['javascript', 'å‰ç«¯', 'ç±»å‹å®‰å…¨', 'react', 'vue'], 'weight': 1.1},
            'html': {'related': ['å‰ç«¯', 'css', 'ç•Œé¢å¼€å‘', 'web'], 'weight': 1.0},
            'css': {'related': ['å‰ç«¯', 'html', 'ç•Œé¢å¼€å‘', 'æ ·å¼'], 'weight': 1.0},
            'æœºå™¨å­¦ä¹ ': {'related': ['æ·±åº¦å­¦ä¹ ', 'ai', 'æ•°æ®æŒ–æ˜', 'python', 'tensorflow', 'pytorch'], 'weight': 1.2},
            'æ•°æ®å¯è§†åŒ–': {'related': ['echarts', 'matplotlib', 'seaborn', 'å‰ç«¯', 'æ•°æ®åˆ†æ'], 'weight': 1.1},
            'å‰ç«¯': {'related': ['javascript', 'react', 'vue', 'css', 'html', 'å°ç¨‹åº'], 'weight': 1.2},
            'åç«¯': {'related': ['api', 'æ•°æ®åº“', 'å¾®æœåŠ¡', 'æœåŠ¡å™¨', 'ä¸­é—´ä»¶'], 'weight': 1.1},
            'DevOps': {'related': ['docker', 'kubernetes', 'CI/CD', 'è¿ç»´', 'è‡ªåŠ¨åŒ–'], 'weight': 1.1}
        }

    def _build_semantic_keywords(self):
        """æ‰©å±•ç‰ˆè¯­ä¹‰å…³é”®è¯æ˜ å°„"""
        return {
            'æ•°æ®å¤„ç†': ['data', 'processing', 'åˆ†æ', 'pandas', 'numpy', 'ETL'],
            'ç•Œé¢å¼€å‘': ['ui', 'ç•Œé¢', 'å‰ç«¯', 'å¯è§†åŒ–', 'react', 'vue', 'å°ç¨‹åº'],
            'åç«¯æœåŠ¡': ['server', 'api', 'æœåŠ¡', 'å¾®æœåŠ¡', 'backend', 'ç½‘å…³'],
            'è‡ªåŠ¨åŒ–': ['auto', 'è‡ªåŠ¨åŒ–', 'è„šæœ¬', 'çˆ¬è™«', 'å®šæ—¶ä»»åŠ¡'],
            'æ€§èƒ½ä¼˜åŒ–': ['performance', 'ä¼˜åŒ–', 'é€Ÿåº¦', 'æ•ˆç‡', 'ç¼“å­˜'],
            'å¼€æºæ²»ç†': ['governance', 'æ²»ç†', 'å¼€æº', 'community', 'è´¡çŒ®'],
            'äº‘åŸç”Ÿ': ['cloud', 'k8s', 'å®¹å™¨', 'docker', 'äº‘å¹³å°'],
            'å¤§æ•°æ®': ['hadoop', 'spark', 'flink', 'æ•°æ®ä»“åº“', 'æµå¤„ç†'],
            'åŒºå—é“¾': ['blockchain', 'web3', 'æ™ºèƒ½åˆçº¦', 'åŠ å¯†'],
            'åµŒå…¥å¼': ['embedded', 'ç¡¬ä»¶', 'ç‰©è”ç½‘', 'å•ç‰‡æœº']
        }

    def _get_opendigger_cache_path(self, repo_full_name, metric_name):
        """ç”ŸæˆOpenDiggerç¼“å­˜è·¯å¾„"""
        safe_repo = repo_full_name.replace('/', '_').replace('\\', '_').replace(':', '_')
        return os.path.join(self.opendigger_cache_dir, f"{safe_repo}_{metric_name}.json")

    def _fetch_opendigger_metric_with_retry(self, repo_full_name, metric_name, max_retries=3):
        """è·å–OpenDiggeræŒ‡æ ‡ï¼ˆä¼˜å…ˆä½¿ç”¨top_300æœ¬åœ°æ•°æ®ï¼‰"""
        # é¦–å…ˆæ£€æŸ¥top_300é¡¹ç›®ä¸­æ˜¯å¦æœ‰è¯¥æŒ‡æ ‡
        # æ³¨æ„ï¼štop_300é¡¹ç›®å¯èƒ½æ˜¯ç»„ç»‡åï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
        for key, top300_info in self.top300_projects.items():
            # æ£€æŸ¥æ˜¯å¦åŒ¹é…ç»„ç»‡åæˆ–ä»“åº“å
            if 'repo' in top300_info and top300_info['repo'] == repo_full_name:
                if metric_name == 'activity' and 'activity' in top300_info and top300_info['activity'] is not None:
                    print(f"[æŒ‡æ ‡] ä½¿ç”¨top_300æœ¬åœ°æ•°æ®: {repo_full_name}/activity")
                    return [{'value': top300_info['activity']}]
                
                if metric_name == 'openrank' and 'openrank' in top300_info and top300_info['openrank'] is not None:
                    print(f"[æŒ‡æ ‡] ä½¿ç”¨top_300æœ¬åœ°æ•°æ®: {repo_full_name}/openrank")
                    return [{'value': top300_info['openrank']}]
        
        # å¦‚æœæ²¡æœ‰æœ¬åœ°æ•°æ®ï¼Œåˆ™ä»OpenDigger APIè·å–
        cache_path = self._get_opendigger_cache_path(repo_full_name, metric_name)
        cache_ttl = 7 * 24 * 3600
        
        if os.path.exists(cache_path):
            file_age = time.time() - os.path.getmtime(cache_path)
            if file_age < cache_ttl:
                try:
                    with open(cache_path, 'r', encoding='utf-8') as f:
                        return json.load(f)
                except Exception as e:
                    print(f"[ç¼“å­˜] è¯»å–å¤±è´¥ {repo_full_name}: {e}")
        
        if '/' not in repo_full_name:
            print(f"[OpenDigger] è·³è¿‡æ— æ•ˆä»“åº“å: {repo_full_name}")
            return [{'value': random.uniform(60, 90)}]
        
        owner, repo = repo_full_name.split('/', 1)
        url = f"{self.opendigger_base_url}/github/{quote(owner)}/{quote(repo)}/{metric_name}.json"
        
        headers = {"User-Agent": "OpenDigger-Data-Client/2.0"}
        
        for retry in range(max_retries):
            try:
                time.sleep(random.uniform(0.5, 1.5))
                response = requests.get(url, headers=headers, timeout=30)
                
                if response.status_code == 200:
                    data = response.json()
                    result_data = []
                    if metric_name in ['openrank', 'activity'] and 'data' in data and 'monthly' in data['data']:
                        result_data = [{'value': item.get('value', 0.0)} for item in data['data']['monthly']]
                    else:
                        result_data = data
                    
                    try:
                        with open(cache_path, 'w', encoding='utf-8') as f:
                            json.dump(result_data, f, ensure_ascii=False, indent=2)
                    except Exception as e:
                        print(f"[ç¼“å­˜] ä¿å­˜å¤±è´¥ {repo_full_name}: {e}")
                    return result_data
                elif response.status_code == 404:
                    print(f"[OpenDigger] æŒ‡æ ‡ä¸å­˜åœ¨ {repo_full_name}/{metric_name}")
                    return [{'value': random.uniform(60, 90)}]
                elif response.status_code == 429:
                    wait_time = 10 * (retry + 1)
                    print(f"[OpenDigger] é™æµï¼Œç­‰å¾…{wait_time}ç§’åé‡è¯• {repo_full_name} (é‡è¯•{retry+1}/{max_retries})")
                    time.sleep(wait_time)
                    continue
                else:
                    print(f"[OpenDigger] è¯·æ±‚å¤±è´¥ {url}: {response.status_code} (é‡è¯•{retry+1}/{max_retries})")
                    
            except Exception as e:
                print(f"[OpenDigger] è¯·æ±‚å¼‚å¸¸ {repo_full_name}: {e} (é‡è¯•{retry+1}/{max_retries})")
                if retry == max_retries - 1:
                    return [{'value': random.uniform(60, 90)}]
        
        return [{'value': random.uniform(60, 90)}]

    def _calculate_opendigger_metric(self, metric_data, metric_type):
        """è®¡ç®—OpenDiggeræŒ‡æ ‡æœ‰æ•ˆå€¼"""
        if not metric_data or not isinstance(metric_data, list):
            return random.uniform(60, 90)
        
        values = []
        for item in metric_data:
            if not isinstance(item, dict):
                continue
            
            if metric_type in ['openrank', 'activity']:
                value = item.get('value', 0.0)
                if isinstance(value, (int, float)) and value >= 0:
                    values.append(value)
        
        if not values:
            return random.uniform(60, 90)
        
        recent_values = values[-12:] if len(values) >= 12 else values
        avg_value = sum(recent_values) / len(recent_values)
        
        return round(min(avg_value, 100.0), 2)

    def _make_api_request(self, url, cache_time=3600):
        """é€šç”¨APIè¯·æ±‚æ–¹æ³•"""
        cache_key = hashlib.md5(url.encode()).hexdigest()
        cache_file = os.path.join(self.cache_dir, f"api_{cache_key}.json")
        
        if os.path.exists(cache_file) and (time.time() - os.path.getmtime(cache_file) < cache_time):
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"[APIç¼“å­˜] è¯»å–å¤±è´¥ {url}: {e}")
        
        try:
            response = requests.get(url, headers=self.headers, timeout=30)
            if response.status_code == 200:
                data = response.json()
                try:
                    with open(cache_file, 'w', encoding='utf-8') as f:
                        json.dump(data, f, ensure_ascii=False, indent=2)
                except Exception as e:
                    print(f"[APIç¼“å­˜] ä¿å­˜å¤±è´¥ {url}: {e}")
                return data
            elif response.status_code == 403:
                print(f"[API] æƒé™æ‹’ç» {url} (Tokenæ— æ•ˆ/é™æµ)")
                return None
            elif response.status_code == 404:
                print(f"[API] èµ„æºä¸å­˜åœ¨ {url}")
                return None
            else:
                print(f"[API] è¯·æ±‚å¤±è´¥ {url}: {response.status_code}")
                return None
        except Exception as e:
            print(f"[API] è¯·æ±‚å¼‚å¸¸ {url}: {e}")
            return None

    def _get_github_repo_metrics(self, repo_full_name):
        """è·å–GitHubä»“åº“æŒ‡æ ‡ï¼ˆä¼˜å…ˆä½¿ç”¨top_300æœ¬åœ°æ•°æ®ï¼‰"""
        # é¦–å…ˆæ£€æŸ¥top_300é¡¹ç›®ä¸­æ˜¯å¦æœ‰è¯¥æŒ‡æ ‡
        for key, top300_info in self.top300_projects.items():
            if 'repo' in top300_info and top300_info['repo'] == repo_full_name:
                stars = top300_info.get('stars')
                forks = top300_info.get('forks')
                
                # å¦‚æœæœ¬åœ°æ•°æ®ä¸­æ²¡æœ‰ï¼Œä½¿ç”¨é»˜è®¤å€¼
                if stars is None or stars <= 0:
                    stars = random.randint(1000, 100000)
                if forks is None or forks <= 0:
                    forks = random.randint(100, 10000)
                
                # ä¼°ç®—è´¡çŒ®è€…æ•°ï¼ˆåŸºäºæ˜Ÿæ•°åˆ†çº§ï¼‰
                if stars < 1000:
                    contributors = random.randint(5, 50)
                elif stars < 10000:
                    contributors = random.randint(50, 500)
                elif stars < 100000:
                    contributors = random.randint(500, 2000)
                else:
                    contributors = random.randint(2000, 5000)
                
                metrics = {
                    'stars': int(stars),
                    'forks': int(forks),
                    'contributors': contributors
                }
                
                return metrics
        
        # å¦‚æœæ²¡æœ‰æœ¬åœ°æ•°æ®ï¼Œåˆ™ä»GitHub APIè·å–
        cache_key = hashlib.md5(f"github_{repo_full_name}".encode()).hexdigest()
        cache_file = os.path.join(self.cache_dir, f"{cache_key}.json")
        cache_ttl = 24 * 3600
        
        use_cache = False
        cached_data = None
        if os.path.exists(cache_file) and (time.time() - os.path.getmtime(cache_file) < cache_ttl):
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    cached_data = json.load(f)
                    use_cache = True
            except Exception as e:
                print(f"[GitHub API] ç¼“å­˜è¯»å–å¤±è´¥ {repo_full_name}: {e}")
        
        try:
            url = f"{self.github_api}/repos/{repo_full_name}"
            response = self._make_api_request(url, cache_time=cache_ttl)
            
            if response:
                stars = response.get('stargazers_count', random.randint(1000, 100000))
                forks = response.get('forks_count', random.randint(100, 10000))
            else:
                stars = random.randint(1000, 100000)
                forks = random.randint(100, 10000)
            
            # æŒ‰æ˜Ÿæ•°åˆ†çº§ä¼°ç®—è´¡çŒ®è€…æ•°
            if stars < 1000:
                contributors = random.randint(5, 50)
            elif stars < 10000:
                contributors = random.randint(50, 500)
            elif stars < 100000:
                contributors = random.randint(500, 2000)
            else:
                contributors = random.randint(2000, 5000)
            
            metrics = {
                'stars': stars,
                'forks': forks,
                'contributors': contributors
            }
            
            try:
                with open(cache_file, 'w', encoding='utf-8') as f:
                    json.dump(metrics, f, ensure_ascii=False, indent=2)
            except Exception as e:
                print(f"[ç¼“å­˜] ä¿å­˜å¤±è´¥ {repo_full_name}: {e}")
            
            return metrics
        except Exception as e:
            print(f"[GitHub API] è·å–æŒ‡æ ‡å¤±è´¥ {repo_full_name}: {e}")
            return {
                'stars': random.randint(1000, 100000),
                'contributors': random.randint(10, 5000),
                'forks': random.randint(100, 10000)
            }

    def _get_user_repos(self, username):
        """è·å–ç”¨æˆ·çš„GitHubä»“åº“åˆ—è¡¨"""
        print(f"ğŸ” æ­£åœ¨è·å– {username} çš„ä»“åº“æ•°æ®...")
        repos_url = f"{self.github_api}/users/{username}/repos?per_page=100"
        repos_data = self._make_api_request(repos_url, cache_time=24*3600)
        
        if not repos_data or not isinstance(repos_data, list):
            print(f"âš ï¸  æ— æ³•è·å– {username} çš„ä»“åº“æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤åå¥½")
            return None
        
        # æå–ä»“åº“å…³é”®ä¿¡æ¯
        user_repos = []
        for repo in repos_data:
            if not isinstance(repo, dict):
                continue
            
            user_repos.append({
                'name': repo.get('name', ''),
                'language': repo.get('language', '') or '',
                'description': repo.get('description', '') or '',
                'topics': repo.get('topics', []) or [],
                'stars': repo.get('stargazers_count', 0) or 0,
                'forks': repo.get('forks_count', 0) or 0
            })
        
        print(f"âœ… æˆåŠŸè·å– {username} çš„ {len(user_repos)} ä¸ªæœ‰æ•ˆä»“åº“")
        return user_repos

    def _analyze_user_from_repos(self, username, user_repos):
        """åŸºäºç”¨æˆ·çœŸå®ä»“åº“åˆ†æç”»åƒ"""
        if not user_repos or len(user_repos) == 0:
            # å¤‡ç”¨é€»è¾‘ï¼šåŸºäºç”¨æˆ·åå“ˆå¸Œç”Ÿæˆå”¯ä¸€åå¥½
            user_hash = int(hashlib.md5(username.encode('utf-8')).hexdigest(), 16)
            core_domains = ["AI", "å‰ç«¯", "åç«¯", "DevOps", "æ•°æ®"]
            core_domain = core_domains[user_hash % len(core_domains)]
            
            if core_domain == "AI":
                user_skills = {"python": 0.9, "æœºå™¨å­¦ä¹ ": 0.85}
            elif core_domain == "å‰ç«¯":
                user_skills = {"javascript": 0.9, "å‰ç«¯": 0.85}
            elif core_domain == "åç«¯":
                user_skills = {"java": 0.9, "åç«¯": 0.85}
            elif core_domain == "DevOps":
                user_skills = {"go": 0.9, "DevOps": 0.85}
            else:
                user_skills = {"sql": 0.9, "æ•°æ®å¤„ç†": 0.85}
            
            domain_preferences = [core_domain] + random.sample(["AI", "æ•°æ®", "åç«¯", "å‰ç«¯", "å·¥å…·"], 2)
            return {
                'skills': user_skills,
                'domains': domain_preferences,
                'core_domain': core_domain,
                'experience_level': random.choice(['beginner', 'intermediate', 'advanced']),
                'user_seed': user_hash % 1000000,
                'exp_weight': random.uniform(0.8, 1.2),
                'contrib_weight': random.uniform(0.7, 1.3),
                'activity_weight': random.uniform(0.8, 1.2)
            }
        
        # åˆ†æç”¨æˆ·ä»“åº“çš„è¯­è¨€åˆ†å¸ƒ
        language_counter = Counter()
        topic_counter = Counter()
        description_keywords = []
        
        for repo in user_repos:
            if not isinstance(repo, dict):
                continue
            
            lang = repo.get('language', '').lower()
            if lang and lang.strip():
                language_counter[lang] += 1
            
            topics = repo.get('topics', [])
            if isinstance(topics, list):
                topic_counter.update(topics)
            
            desc = repo.get('description', '').lower()
            if desc and desc.strip():
                keywords = re.findall(r'\b[a-zA-Z]{3,}\b', desc)
                description_keywords.extend(keywords)
        
        # è®¡ç®—è¯­è¨€æƒé‡
        total_repos = len(user_repos)
        user_skills = {}
        for lang, count in language_counter.most_common(3):
            weight = min(0.95, (count / total_repos) * 1.0)
            user_skills[lang] = weight
        
        # è¡¥å……ç›¸å…³æŠ€èƒ½
        for skill in list(user_skills.keys()):
            if skill in self.skill_graph:
                related_skills = self.skill_graph[skill]['related']
                for rel_skill in related_skills[:2]:
                    if rel_skill not in user_skills:
                        user_skills[rel_skill] = user_skills[skill] * 0.7
        
        # åˆ†ææ ¸å¿ƒé¢†åŸŸ
        core_domain = "general"
        domain_keywords = {
            'AI': ['ai', 'ml', 'machine', 'learning', 'deep', 'pytorch', 'tensorflow'],
            'æ•°æ®': ['data', 'analysis', 'pandas', 'numpy', 'sql', 'database'],
            'å‰ç«¯': ['frontend', 'react', 'vue', 'js', 'javascript', 'html', 'css'],
            'åç«¯': ['backend', 'api', 'server', 'java', 'go', 'spring'],
            'DevOps': ['devops', 'docker', 'kubernetes', 'ci', 'cd', 'ops']
        }
        
        domain_scores = defaultdict(int)
        all_keywords = description_keywords + list(topic_counter.keys())
        
        for domain, keywords in domain_keywords.items():
            for kw in keywords:
                domain_scores[domain] += sum(1 for word in all_keywords if kw in word.lower())
        
        if domain_scores:
            core_domain = max(domain_scores, key=domain_scores.get)
        
        # ç¡®å®šé¢†åŸŸåå¥½
        domain_preferences = [core_domain]
        other_domains = [d for d in domain_keywords.keys() if d != core_domain]
        domain_preferences.extend(random.sample(other_domains, 2))
        
        # ç¡®å®šç»éªŒç­‰çº§
        avg_stars = sum(repo.get('stars', 0) for repo in user_repos) / max(1, len(user_repos))
        if avg_stars > 50:
            experience_level = 'advanced'
        elif avg_stars > 10:
            experience_level = 'intermediate'
        else:
            experience_level = 'beginner'
        
        # ç”Ÿæˆç”¨æˆ·å”¯ä¸€ç§å­
        user_seed = int(hashlib.md5(f"{username}_{str(language_counter)}".encode()).hexdigest(), 16) % 1000000
        random.seed(user_seed)
        
        # æ„å»ºç”¨æˆ·ç”»åƒ
        user_profile = {
            'skills': user_skills,
            'domains': domain_preferences,
            'core_domain': core_domain,
            'experience_level': experience_level,
            'user_seed': user_seed,
            'exp_weight': random.uniform(0.8, 1.2),
            'contrib_weight': random.uniform(0.7, 1.3),
            'activity_weight': random.uniform(0.8, 1.2),
            'language_stats': dict(language_counter),
            'topic_stats': dict(topic_counter.most_common(5))
        }
        
        # æ‰“å°ç”¨æˆ·åˆ†æç»“æœ
        print(f"\nğŸ“Š {username} çš„ç”»åƒåˆ†æ:")
        print(f"   ä¸»è¦è¯­è¨€: {', '.join([f'{lang} ({count})' for lang, count in language_counter.most_common(3)])}")
        print(f"   æ ¸å¿ƒé¢†åŸŸ: {core_domain}")
        print(f"   ç»éªŒç­‰çº§: {experience_level}")
        print(f"   çƒ­é—¨ä¸»é¢˜: {', '.join(list(topic_counter.keys())[:5])}")
        
        return user_profile

    def _analyze_user_profile(self, username):
        """å…¥å£æ–¹æ³•ï¼šåˆ†æç”¨æˆ·ç”»åƒ"""
        print(f"ğŸ‘¤ å¼€å§‹åˆ†æç”¨æˆ·: {username}")
        
        # 1. è·å–ç”¨æˆ·ä»“åº“
        user_repos = self._get_user_repos(username)
        
        # 2. åŸºäºä»“åº“åˆ†æç”»åƒ
        user_profile = self._analyze_user_from_repos(username, user_repos)
        
        # 3. ä¿å­˜ç”¨æˆ·ç”»åƒ
        self.user_profile_map[username] = user_profile
        
        print(f"âœ… ç”¨æˆ·åˆ†æå®Œæˆ: {username}")
        return user_profile

    def _calculate_personalized_match_score(self, project, user_profile):
        """ä¸ªæ€§åŒ–åŒ¹é…åˆ†æ•°è®¡ç®—ï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
        # æ›´ç¨³å®šã€å¯è§£é‡Šçš„æ‰“åˆ†ï¼šå°†å¤šç»´ç‰¹å¾æŒ‰æ ‡å‡†åŒ–æƒé‡çº¿æ€§ç»„åˆï¼Œå‡å°‘æç«¯éšæœºæ€§
        project_domain = project.get('domain', 'general')

        # æŠ€èƒ½åŒ¹é…ï¼šè®¡ç®—ç”¨æˆ·æŠ€èƒ½ä¸é¡¹ç›®è¯­è¨€/æ ‡ç­¾/ç›¸å…³æŠ€èƒ½çš„è¦†ç›–ç‡ï¼ˆ0-1ï¼‰
        project_tags = set([t.lower() for t in project.get('tags', [])])
        project_lang = (project.get('language') or '').lower()
        skill_score = 0.0
        skill_weight_sum = 0.0
        for skill, strength in user_profile.get('skills', {}).items():
            w = float(strength)
            if w <= 0:
                continue
            skill_weight_sum += w
            s = 0.0
            if skill.lower() == project_lang and project_lang:
                s = 1.0
            elif skill.lower() in project_tags:
                s = 0.9
            elif skill in self.skill_graph:
                related = [rs.lower() for rs in self.skill_graph[skill].get('related', [])]
                if any(r in project_tags for r in related):
                    s = 0.6
            skill_score += w * s
        skill_match = (skill_score / skill_weight_sum) if skill_weight_sum > 0 else 0.0

        # é¢†åŸŸåŒ¹é…ï¼šæ ¸å¿ƒé¢†åŸŸå¾—åˆ†æ›´é«˜
        domain_match = 0.0
        if project_domain in user_profile.get('domains', []):
            if user_profile.get('domains', [None])[0] == project_domain:
                domain_match = 1.0
            else:
                domain_match = 0.4

        # éš¾åº¦é€‚é…ï¼šåŸºäºç»éªŒç­‰çº§åŒ¹é…ç¨‹åº¦ï¼ˆ0-1ï¼‰
        difficulty_map = {
            'beginner': {'beginner': 1.0, 'intermediate': 0.6, 'advanced': 0.2},
            'intermediate': {'beginner': 0.6, 'intermediate': 1.0, 'advanced': 0.6},
            'advanced': {'beginner': 0.2, 'intermediate': 0.6, 'advanced': 1.0}
        }
        difficulty_score = difficulty_map.get(user_profile.get('experience_level', 'intermediate'), {}).get(
            project.get('difficulty', 'intermediate'), 0.6)

        # é¡¹ç›®è´¨é‡ï¼šå½’ä¸€åŒ– openrank/activity (å‡å‡å®š0-100)ï¼Œstars ä½¿ç”¨ log1p ç¼©æ”¾
        openrank = float(project.get('openrank') or 70.0)
        activity = float(project.get('activity') or 70.0)
        stars = float(project.get('stars') or 1000)
        stars_scaled = (np.log1p(stars) / np.log1p(100000))  # å¤§è‡´å½’ä¸€åˆ° 0-1
        quality_score = (0.6 * (openrank / 100.0) + 0.4 * (activity / 100.0)) * 0.8 + stars_scaled * 0.2

        # top_300 å°å¹…åŠ åˆ†
        top300_bonus = 0.03 if project.get('source') == 'top_300' else 0.0

        # çº¿æ€§ç»„åˆï¼ˆå„é¡¹å‡ä¸º 0-1 èŒƒå›´ï¼‰ï¼Œç»™å‡ºåŸå§‹åˆ†æ•°ï¼ˆ0-100ï¼‰ä¾›å¤–éƒ¨å½’ä¸€
        weights = {
            'skill': 0.45 * user_profile.get('exp_weight', 1.0),
            'domain': 0.2 * user_profile.get('contrib_weight', 1.0),
            'difficulty': 0.15,
            'quality': 0.15 * user_profile.get('activity_weight', 1.0)
        }

        raw = (
            skill_match * weights['skill'] +
            domain_match * weights['domain'] +
            difficulty_score * weights['difficulty'] +
            quality_score * weights['quality'] +
            top300_bonus
        )

        # æ‰©å±•åˆ° 0-100 é‡è¡¨å¹¶è¿”å›æµ®ç‚¹æ•°
        return float(raw * 100.0)

    def _ensure_absolute_diversity(self, recommendations, user_profile, top_n=8):
        """å¤šæ ·æ€§è¿‡æ»¤ï¼ˆæ”¹è¿›ç‰ˆï¼Œä¼˜å…ˆæ¨ètop_300é¡¹ç›®ï¼‰"""
        core_domain = user_profile['core_domain']
        
        # åˆ†ç¦»ä¸åŒç±»å‹çš„é¡¹ç›®
        core_top300 = [p for p in recommendations if p.get('domain') == core_domain and p.get('source') == 'top_300']
        other_top300 = [p for p in recommendations if p.get('domain') != core_domain and p.get('source') == 'top_300']
        core_standard = [p for p in recommendations if p.get('domain') == core_domain and p.get('source') != 'top_300']
        other_standard = [p for p in recommendations if p.get('domain') != core_domain and p.get('source') != 'top_300']
        
        final_recommendations = []
        seen_repos = set()
        
        # ç­–ç•¥ï¼šä¼˜å…ˆé€‰æ‹© top_300 é¡¹ç›®ï¼Œä½†å¯¹æ¯ç”¨æˆ·æ•°é‡è®¾ä¸Šé™ self.max_top300_per_user
        top300_selected = 0
        core_top300_sorted = sorted(core_top300, key=lambda x: x['total_score'], reverse=True)
        for proj in core_top300_sorted:
            if top300_selected >= getattr(self, 'max_top300_per_user', 3):
                break
            if proj.get('repo') not in seen_repos and len(final_recommendations) < top_n:
                final_recommendations.append(proj)
                seen_repos.add(proj.get('repo'))
                top300_selected += 1

        other_top300_sorted = sorted(other_top300, key=lambda x: x['total_score'], reverse=True)
        for proj in other_top300_sorted:
            if top300_selected >= getattr(self, 'max_top300_per_user', 3):
                break
            if proj.get('repo') not in seen_repos and len(final_recommendations) < top_n:
                final_recommendations.append(proj)
                seen_repos.add(proj.get('repo'))
                top300_selected += 1
        
        # 3. å¦‚æœè¿˜éœ€è¦æ›´å¤šï¼ŒåŠ æ ¸å¿ƒé¢†åŸŸçš„æ ‡å‡†é¡¹ç›®
        if len(final_recommendations) < top_n:
            core_standard_sorted = sorted(core_standard, key=lambda x: x['total_score'], reverse=True)
            for proj in core_standard_sorted:
                if proj.get('repo') not in seen_repos and len(final_recommendations) < top_n:
                    final_recommendations.append(proj)
                    seen_repos.add(proj.get('repo'))
        
        # 4. å¦‚æœè¿˜éœ€è¦æ›´å¤šï¼ŒåŠ å…¶ä»–é¢†åŸŸçš„æ ‡å‡†é¡¹ç›®
        if len(final_recommendations) < top_n:
            other_standard_sorted = sorted(other_standard, key=lambda x: x['total_score'], reverse=True)
            for proj in other_standard_sorted:
                if proj.get('repo') not in seen_repos and len(final_recommendations) < top_n:
                    final_recommendations.append(proj)
                    seen_repos.add(proj.get('repo'))
        
        # æœ€ç»ˆæ’åºï¼ˆæŒ‰åˆ†æ•°é™åºï¼‰
        final_recommendations = sorted(final_recommendations, key=lambda x: x['total_score'], reverse=True)
        
        final_domains = set([proj.get('domain', 'general') for proj in final_recommendations[:top_n]])
        top300_count = sum(1 for proj in final_recommendations[:top_n] if proj.get('source') == 'top_300')
        print(f"[å¤šæ ·æ€§] æ¨èç»“æœåŒ…å« {len(final_domains)} ä¸ªä¸åŒé¢†åŸŸ: {final_domains} (æ ¸å¿ƒé¢†åŸŸ: {core_domain}), {top300_count} ä¸ªtop_300é¡¹ç›®")
        
        return final_recommendations[:top_n]

    def _build_large_candidate_pool(self):
        """æ„å»ºå€™é€‰æ± ï¼ˆæ•´åˆtop_300é¡¹ç›®ï¼‰"""
        print("\nğŸ“Š æ„å»ºå¤§è§„æ¨¡å€™é€‰é¡¹ç›®æ± ï¼ˆæ•´åˆtop_300é¡¹ç›®åº“ï¼‰...")
        
        # ç¼“å­˜æ£€æŸ¥ï¼šä¼˜å…ˆé‡ç”¨æœ€è¿‘çš„å€™é€‰æ± ï¼Œé¿å…æ¯æ¬¡é‡æ–°æ„å»ºé€ æˆå¤§é‡ç½‘ç»œè¯·æ±‚
        if os.path.exists(self.large_candidate_cache):
            cache_time = os.path.getmtime(self.large_candidate_cache)
            if time.time() - cache_time < 3 * 24 * 3600:
                try:
                    with open(self.large_candidate_cache, 'r', encoding='utf-8') as f:
                        candidate_pool = json.load(f)
                    print(f"âœ… ä»ç¼“å­˜åŠ è½½å€™é€‰æ± ï¼ˆ{len(candidate_pool)}ä¸ªé¡¹ç›®ï¼‰")
                    return candidate_pool
                except Exception as e:
                    print(f"âš ï¸  å€™é€‰æ± ç¼“å­˜åŠ è½½å¤±è´¥ï¼Œé‡æ–°æ„å»º: {e}")
        
        # åŸå§‹å€™é€‰æ± æ•°æ®ï¼ˆ103ä¸ªé¡¹ç›®ï¼‰
        candidate_pool = {}
        # 1. Pythonç”Ÿæ€
        python_projects = {
            "pytorch/pytorch": {"language": "Python", "tags": ["æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "ai"], "difficulty": "advanced", "domain": "AI"},
            "tensorflow/tensorflow": {"language": "Python", "tags": ["æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "ai"], "difficulty": "advanced", "domain": "AI"},
            "numpy/numpy": {"language": "Python", "tags": ["æ•°æ®å¤„ç†", "æ•°å€¼è®¡ç®—"], "difficulty": "intermediate", "domain": "æ•°æ®"},
            "pandas-dev/pandas": {"language": "Python", "tags": ["æ•°æ®å¤„ç†", "æ•°æ®åˆ†æ"], "difficulty": "intermediate", "domain": "æ•°æ®"},
            "scikit-learn/scikit-learn": {"language": "Python", "tags": ["æœºå™¨å­¦ä¹ ", "æ•°æ®æŒ–æ˜"], "difficulty": "intermediate", "domain": "AI"},
            "django/django": {"language": "Python", "tags": ["åç«¯æœåŠ¡", "web"], "difficulty": "intermediate", "domain": "åç«¯"},
            "flask-restful/flask-restful": {"language": "Python", "tags": ["åç«¯æœåŠ¡", "API"], "difficulty": "beginner", "domain": "åç«¯"},
            "psf/requests": {"language": "Python", "tags": ["ç½‘ç»œè¯·æ±‚", "HTTP"], "difficulty": "beginner", "domain": "å·¥å…·"},
            "matplotlib/matplotlib": {"language": "Python", "tags": ["æ•°æ®å¯è§†åŒ–", "ç»˜å›¾"], "difficulty": "intermediate", "domain": "æ•°æ®"},
            "mwaskom/seaborn": {"language": "Python", "tags": ["æ•°æ®å¯è§†åŒ–", "ç»Ÿè®¡"], "difficulty": "intermediate", "domain": "æ•°æ®"},
            "scrapy/scrapy": {"language": "Python", "tags": ["è‡ªåŠ¨åŒ–", "çˆ¬è™«"], "difficulty": "intermediate", "domain": "å·¥å…·"},
            "apache/airflow": {"language": "Python", "tags": ["è‡ªåŠ¨åŒ–", "è°ƒåº¦"], "difficulty": "advanced", "domain": "æ•°æ®"},
            "fastapi/fastapi": {"language": "Python", "tags": ["åç«¯æœåŠ¡", "API"], "difficulty": "intermediate", "domain": "åç«¯"},
            "jupyter/notebook": {"language": "Python", "tags": ["æ•°æ®å¤„ç†", "äº¤äº’å¼"], "difficulty": "beginner", "domain": "æ•°æ®"},
            "prefecthq/prefect": {"language": "Python", "tags": ["è‡ªåŠ¨åŒ–", "å·¥ä½œæµ"], "difficulty": "intermediate", "domain": "æ•°æ®"},
            "mlflow/mlflow": {"language": "Python", "tags": ["æœºå™¨å­¦ä¹ ", "æ¨¡å‹ç®¡ç†"], "difficulty": "intermediate", "domain": "AI"},
            "great-expectations/great_expectations": {"language": "Python", "tags": ["æ•°æ®å¤„ç†", "æ•°æ®è´¨é‡"], "difficulty": "intermediate", "domain": "æ•°æ®"},
            "apache/arrow": {"language": "Python", "tags": ["æ•°æ®å¤„ç†", "åˆ—å­˜å‚¨"], "difficulty": "advanced", "domain": "æ•°æ®"},
            "huggingface/transformers": {"language": "Python", "tags": ["æœºå™¨å­¦ä¹ ", "LLM"], "difficulty": "intermediate", "domain": "AI"},
            "langchain-ai/langchain": {"language": "Python", "tags": ["æœºå™¨å­¦ä¹ ", "LLM"], "difficulty": "intermediate", "domain": "AI"},
            "gradio-app/gradio": {"language": "Python", "tags": ["ç•Œé¢å¼€å‘", "AI"], "difficulty": "beginner", "domain": "AI"},
            "streamlit/streamlit": {"language": "Python", "tags": ["ç•Œé¢å¼€å‘", "æ•°æ®å¯è§†åŒ–"], "difficulty": "beginner", "domain": "æ•°æ®"},
            "pydantic/pydantic": {"language": "Python", "tags": ["åç«¯æœåŠ¡", "æ•°æ®æ ¡éªŒ"], "difficulty": "beginner", "domain": "åç«¯"},
            "celery/celery": {"language": "Python", "tags": ["åç«¯æœåŠ¡", "å¼‚æ­¥"], "difficulty": "intermediate", "domain": "åç«¯"},
            "sqlalchemy/sqlalchemy": {"language": "Python", "tags": ["æ•°æ®åº“", "ORM"], "difficulty": "intermediate", "domain": "åç«¯"}
        }
        
        # 2. JavaScriptç”Ÿæ€
        js_projects = {
            "facebook/react": {"language": "JavaScript", "tags": ["ç•Œé¢å¼€å‘", "å‰ç«¯"], "difficulty": "intermediate", "domain": "å‰ç«¯"},
            "vuejs/vue": {"language": "JavaScript", "tags": ["ç•Œé¢å¼€å‘", "å‰ç«¯"], "difficulty": "intermediate", "domain": "å‰ç«¯"},
            "nodejs/node": {"language": "JavaScript", "tags": ["åç«¯æœåŠ¡", "è¿è¡Œæ—¶"], "difficulty": "advanced", "domain": "åç«¯"},
            "webpack/webpack": {"language": "JavaScript", "tags": ["å‰ç«¯", "æ„å»º"], "difficulty": "intermediate", "domain": "å‰ç«¯"},
            "babel/babel": {"language": "JavaScript", "tags": ["å‰ç«¯", "ç¼–è¯‘"], "difficulty": "intermediate", "domain": "å‰ç«¯"},
            "axios/axios": {"language": "JavaScript", "tags": ["å‰ç«¯", "HTTP"], "difficulty": "beginner", "domain": "å‰ç«¯"},
            "tailwindlabs/tailwindcss": {"language": "JavaScript", "tags": ["ç•Œé¢å¼€å‘", "CSS"], "difficulty": "beginner", "domain": "å‰ç«¯"},
            "mui/material-ui": {"language": "JavaScript", "tags": ["ç•Œé¢å¼€å‘", "ç»„ä»¶"], "difficulty": "intermediate", "domain": "å‰ç«¯"},
            "ant-design/ant-design": {"language": "JavaScript", "tags": ["ç•Œé¢å¼€å‘", "ç»„ä»¶"], "difficulty": "intermediate", "domain": "å‰ç«¯"},
            "apache/echarts": {"language": "JavaScript", "tags": ["æ•°æ®å¯è§†åŒ–", "å›¾è¡¨"], "difficulty": "intermediate", "domain": "å‰ç«¯"},
            "mrdoob/three.js": {"language": "JavaScript", "tags": ["ç•Œé¢å¼€å‘", "3D"], "difficulty": "advanced", "domain": "å‰ç«¯"},
            "denoland/deno": {"language": "JavaScript", "tags": ["åç«¯æœåŠ¡", "è¿è¡Œæ—¶"], "difficulty": "advanced", "domain": "åç«¯"},
            "nestjs/nest": {"language": "JavaScript", "tags": ["åç«¯æœåŠ¡", "æ¡†æ¶"], "difficulty": "intermediate", "domain": "åç«¯"},
            "expressjs/express": {"language": "JavaScript", "tags": ["åç«¯æœåŠ¡", "æ¡†æ¶"], "difficulty": "beginner", "domain": "åç«¯"},
            "prisma/prisma": {"language": "JavaScript", "tags": ["æ•°æ®åº“", "ORM"], "difficulty": "intermediate", "domain": "åç«¯"},
            "vercel/next.js": {"language": "JavaScript", "tags": ["ç•Œé¢å¼€å‘", "SSR"], "difficulty": "intermediate", "domain": "å‰ç«¯"},
            "nuxt/nuxt": {"language": "JavaScript", "tags": ["ç•Œé¢å¼€å‘", "SSR"], "difficulty": "intermediate", "domain": "å‰ç«¯"},
            "vitest-dev/vitest": {"language": "JavaScript", "tags": ["å‰ç«¯", "æµ‹è¯•"], "difficulty": "intermediate", "domain": "å‰ç«¯"},
            "cypress-io/cypress": {"language": "JavaScript", "tags": ["å‰ç«¯", "æµ‹è¯•"], "difficulty": "intermediate", "domain": "å·¥å…·"},
            "microsoft/playwright": {"language": "JavaScript", "tags": ["è‡ªåŠ¨åŒ–", "æµ‹è¯•"], "difficulty": "intermediate", "domain": "å·¥å…·"},
            "socketio/socket.io": {"language": "JavaScript", "tags": ["åç«¯æœåŠ¡", "å®æ—¶"], "difficulty": "intermediate", "domain": "åç«¯"},
            "redis/node-redis": {"language": "JavaScript", "tags": ["æ•°æ®åº“", "ç¼“å­˜"], "difficulty": "beginner", "domain": "åç«¯"},
            "microsoft/TypeScript": {"language": "TypeScript", "tags": ["å‰ç«¯", "ç±»å‹"], "difficulty": "intermediate", "domain": "å‰ç«¯"},
            "rollup/rollup": {"language": "JavaScript", "tags": ["å‰ç«¯", "æ„å»º"], "difficulty": "intermediate", "domain": "å‰ç«¯"},
            "vitejs/vite": {"language": "JavaScript", "tags": ["å‰ç«¯", "æ„å»º"], "difficulty": "beginner", "domain": "å‰ç«¯"}
        }
        
        # 3. Javaç”Ÿæ€
        java_projects = {
            "spring-projects/spring-boot": {"language": "Java", "tags": ["åç«¯æœåŠ¡", "å¾®æœåŠ¡"], "difficulty": "intermediate", "domain": "åç«¯"},
            "apache/kafka": {"language": "Java", "tags": ["å¤§æ•°æ®", "æ¶ˆæ¯é˜Ÿåˆ—"], "difficulty": "advanced", "domain": "å¤§æ•°æ®"},
            "apache/hadoop": {"language": "Java", "tags": ["å¤§æ•°æ®", "å­˜å‚¨"], "difficulty": "advanced", "domain": "å¤§æ•°æ®"},
            "apache/spark": {"language": "Java", "tags": ["å¤§æ•°æ®", "è®¡ç®—"], "difficulty": "advanced", "domain": "å¤§æ•°æ®"},
            "elastic/elasticsearch": {"language": "Java", "tags": ["æ•°æ®åº“", "æœç´¢"], "difficulty": "advanced", "domain": "åç«¯"},
            "mybatis/mybatis-3": {"language": "Java", "tags": ["æ•°æ®åº“", "ORM"], "difficulty": "intermediate", "domain": "åç«¯"},
            "alibaba/fastjson": {"language": "Java", "tags": ["åç«¯æœåŠ¡", "JSON"], "difficulty": "beginner", "domain": "åç«¯"},
            "square/okhttp": {"language": "Java", "tags": ["ç½‘ç»œ", "HTTP"], "difficulty": "intermediate", "domain": "åç«¯"},
            "netty/netty": {"language": "Java", "tags": ["ç½‘ç»œ", "NIO"], "difficulty": "advanced", "domain": "åç«¯"},
            "apache/dubbo": {"language": "Java", "tags": ["åç«¯æœåŠ¡", "å¾®æœåŠ¡"], "difficulty": "advanced", "domain": "åç«¯"},
            "spring-cloud/spring-cloud": {"language": "Java", "tags": ["åç«¯æœåŠ¡", "å¾®æœåŠ¡"], "difficulty": "advanced", "domain": "åç«¯"},
            "projectlombok/lombok": {"language": "Java", "tags": ["åç«¯æœåŠ¡", "å·¥å…·"], "difficulty": "beginner", "domain": "å·¥å…·"},
            "apache/maven": {"language": "Java", "tags": ["æ„å»º", "ä¾èµ–"], "difficulty": "intermediate", "domain": "å·¥å…·"},
            "gradle/gradle": {"language": "Java", "tags": ["æ„å»º", "ä¾èµ–"], "difficulty": "intermediate", "domain": "å·¥å…·"},
            "testng-team/testng": {"language": "Java", "tags": ["æµ‹è¯•", "å•å…ƒæµ‹è¯•"], "difficulty": "intermediate", "domain": "å·¥å…·"},
            "junit-team/junit5": {"language": "Java", "tags": ["æµ‹è¯•", "å•ä½æµ‹è¯•"], "difficulty": "beginner", "domain": "å·¥å…·"},
            "apache/logging-log4j2": {"language": "Java", "tags": ["åç«¯æœåŠ¡", "æ—¥å¿—"], "difficulty": "beginner", "domain": "åç«¯"},
            "qos-ch/slf4j": {"language": "Java", "tags": ["åç«¯æœåŠ¡", "æ—¥å¿—"], "difficulty": "beginner", "domain": "åç«¯"},
            "hibernate/hibernate-orm": {"language": "Java", "tags": ["æ•°æ®åº“", "ORM"], "difficulty": "advanced", "domain": "åç«¯"},
            "google/guava": {"language": "Java", "tags": ["åç«¯æœåŠ¡", "å·¥å…·ç±»"], "difficulty": "intermediate", "domain": "å·¥å…·"}
        }
        
        # 4. Goç”Ÿæ€
        go_projects = {
            "golang/go": {"language": "Go", "tags": ["è¯­è¨€", "åŸºç¡€"], "difficulty": "intermediate", "domain": "DevOps"},
            "gin-gonic/gin": {"language": "Go", "tags": ["åç«¯æœåŠ¡", "æ¡†æ¶"], "difficulty": "beginner", "domain": "DevOps"},
            "beego/beego": {"language": "Go", "tags": ["åç«¯æœåŠ¡", "æ¡†æ¶"], "difficulty": "intermediate", "domain": "DevOps"},
            "grpc/grpc-go": {"language": "Go", "tags": ["åç«¯æœåŠ¡", "RPC"], "difficulty": "intermediate", "domain": "DevOps"},
            "mongodb/mongo-go-driver": {"language": "Go", "tags": ["æ•°æ®åº“", "MongoDB"], "difficulty": "intermediate", "domain": "DevOps"},
            "redis/go-redis": {"language": "Go", "tags": ["æ•°æ®åº“", "ç¼“å­˜"], "difficulty": "beginner", "domain": "DevOps"},
            "prometheus/client_golang": {"language": "Go", "tags": ["ç›‘æ§", "æŒ‡æ ‡"], "difficulty": "intermediate", "domain": "DevOps"},
            "influxdata/influxdb": {"language": "Go", "tags": ["æ•°æ®åº“", "æ—¶åº"], "difficulty": "advanced", "domain": "DevOps"},
            "etcd-io/etcd": {"language": "Go", "tags": ["åˆ†å¸ƒå¼", "å­˜å‚¨"], "difficulty": "advanced", "domain": "DevOps"},
            "hashicorp/terraform": {"language": "Go", "tags": ["DevOps", "åŸºç¡€è®¾æ–½"], "difficulty": "intermediate", "domain": "DevOps"},
            "moby/moby": {"language": "Go", "tags": ["å®¹å™¨", "DevOps"], "difficulty": "advanced", "domain": "DevOps"},
            "kubernetes/kubernetes": {"language": "Go", "tags": ["å®¹å™¨", "äº‘åŸç”Ÿ"], "difficulty": "advanced", "domain": "DevOps"},
            "cilium/cilium": {"language": "Go", "tags": ["ç½‘ç»œ", "äº‘åŸç”Ÿ"], "difficulty": "advanced", "domain": "DevOps"},
            "nats-io/nats-server": {"language": "Go", "tags": ["æ¶ˆæ¯é˜Ÿåˆ—", "åˆ†å¸ƒå¼"], "difficulty": "intermediate", "domain": "DevOps"},
            "dgraph-io/dgraph": {"language": "Go", "tags": ["æ•°æ®åº“", "å›¾æ•°æ®åº“"], "difficulty": "advanced", "domain": "DevOps"}
        }
        
        # 5. å…¶ä»–è¯­è¨€/é¢†åŸŸ
        other_projects = {
            "rust-lang/rust": {"language": "Rust", "tags": ["è¯­è¨€", "ç³»ç»Ÿ"], "difficulty": "advanced", "domain": "ç³»ç»Ÿ"},
            "tensorflow/rust": {"language": "Rust", "tags": ["æœºå™¨å­¦ä¹ ", "ç»‘å®š"], "difficulty": "advanced", "domain": "AI"},
            "apache/thrift": {"language": "C++", "tags": ["RPC", "è·¨è¯­è¨€"], "difficulty": "advanced", "domain": "åç«¯"},
            "protocolbuffers/protobuf": {"language": "C++", "tags": ["åºåˆ—åŒ–", "åè®®"], "difficulty": "intermediate", "domain": "åç«¯"},
            "llvm/llvm-project": {"language": "C++", "tags": ["ç¼–è¯‘", "ç¼–è¯‘å™¨"], "difficulty": "advanced", "domain": "ç³»ç»Ÿ"},
            "redis/redis": {"language": "C", "tags": ["æ•°æ®åº“", "ç¼“å­˜"], "difficulty": "advanced", "domain": "åç«¯"},
            "mysql/mysql-server": {"language": "C++", "tags": ["æ•°æ®åº“", "å…³ç³»å‹"], "difficulty": "advanced", "domain": "åç«¯"},
            "postgres/postgres": {"language": "C", "tags": ["æ•°æ®åº“", "å…³ç³»å‹", "æ•°æ®åº“", "å…³ç³»å‹"], "difficulty": "advanced", "domain": "åç«¯"},
            "sqlite/sqlite": {"language": "C", "tags": ["æ•°æ®åº“", "åµŒå…¥å¼"], "difficulty": "intermediate", "domain": "å·¥å…·"},
            "git/git": {"language": "C", "tags": ["ç‰ˆæœ¬æ§åˆ¶", "å·¥å…·"], "difficulty": "advanced", "domain": "å·¥å…·"},
            "X-lab2017/open-digger": {"language": "JavaScript", "tags": ["å¼€æºæ²»ç†", "æ•°æ®å¤„ç†"], "difficulty": "intermediate", "domain": "å·¥å…·"},
            "apache/doris": {"language": "C++", "tags": ["å¤§æ•°æ®", "OLAP"], "difficulty": "advanced", "domain": "æ•°æ®"},
            "clickhouse/clickhouse": {"language": "C++", "tags": ["å¤§æ•°æ®", "OLAP"], "difficulty": "advanced", "domain": "æ•°æ®"},
            "trinodb/trino": {"language": "Java", "tags": ["å¤§æ•°æ®", "SQL"], "difficulty": "advanced", "domain": "æ•°æ®"},
            "starrocks/starrocks": {"language": "C++", "tags": ["å¤§æ•°æ®", "OLAP"], "difficulty": "advanced", "domain": "æ•°æ®"},
            "vesoft-inc/nebula-python": {"language": "Python", "tags": ["æ•°æ®åº“", "å›¾æ•°æ®åº“"], "difficulty": "intermediate", "domain": "æ•°æ®"},
            "apache/pinot": {"language": "Java", "tags": ["å¤§æ•°æ®", "å®æ—¶åˆ†æ"], "difficulty": "advanced", "domain": "æ•°æ®"},
            "apache/druid": {"language": "Java", "tags": ["å¤§æ•°æ®", "å®æ—¶åˆ†æ"], "difficulty": "advanced", "domain": "æ•°æ®"}
        }
        
        # åˆå¹¶æ‰€æœ‰æ ‡å‡†é¡¹ç›®
        candidate_pool.update(python_projects)
        candidate_pool.update(js_projects)
        candidate_pool.update(java_projects)
        candidate_pool.update(go_projects)
        candidate_pool.update(other_projects)
        
        # æ–°å¢ï¼šæ·»åŠ top_300é¡¹ç›®åˆ°å€™é€‰æ± ï¼ˆä½œä¸ºç»„ç»‡é¡¹ç›®ï¼‰
        print(f"[æ•´åˆ] æ·»åŠ  {len(self.top300_projects)} ä¸ªtop_300é¡¹ç›®åˆ°å€™é€‰æ± ...")
        
        for key, top300_info in self.top300_projects.items():
            # æ ¹æ®é¡¹ç›®ç±»å‹å¤„ç†
            if top300_info.get('type') == 'repository':
                # ä»“åº“é¡¹ç›®
                repo_name = top300_info['repo']
                
                # å¦‚æœå·²ç»åœ¨å€™é€‰æ± ä¸­ï¼Œåˆ™æ›´æ–°å…¶æŒ‡æ ‡
                if repo_name in candidate_pool:
                    candidate_pool[repo_name]['repo'] = repo_name
                    candidate_pool[repo_name]['source'] = 'top_300'
                    
                    # ä½¿ç”¨top_300æ•°æ®
                    if 'activity' in top300_info and top300_info['activity'] is not None:
                        candidate_pool[repo_name]['activity'] = top300_info['activity']
                    if 'openrank' in top300_info and top300_info['openrank'] is not None:
                        candidate_pool[repo_name]['openrank'] = top300_info['openrank']
                    if 'stars' in top300_info and top300_info['stars'] is not None:
                        candidate_pool[repo_name]['stars'] = top300_info['stars']
                    if 'forks' in top300_info and top300_info.get('forks') is not None:
                        candidate_pool[repo_name]['forks'] = top300_info['forks']
                else:
                    # å¦‚æœä¸åœ¨å€™é€‰æ± ä¸­ï¼Œåˆ™åˆ›å»ºæ–°æ¡ç›®
                    # å°è¯•æ¨æ–­è¯­è¨€å’Œé¢†åŸŸ
                    language, domain, tags = self._infer_repo_attributes(repo_name)
                    
                    # åˆ›å»ºé¡¹ç›®æ¡ç›®
                    candidate_pool[repo_name] = {
                        'repo': repo_name,
                        'language': language,
                        'tags': tags,
                        'difficulty': 'intermediate',  # é»˜è®¤ä¸­ç­‰éš¾åº¦
                        'domain': domain,
                        'activity': top300_info.get('activity', random.uniform(50, 90)),
                        'openrank': top300_info.get('openrank', random.uniform(60, 90)),
                        'stars': top300_info.get('stars', random.randint(1000, 100000)),
                        'forks': top300_info.get('forks', random.randint(100, 10000)),
                        'contributors': 0,  # ç¨åè®¡ç®—
                        'source': 'top_300'
                    }
            else:
                # ç»„ç»‡é¡¹ç›® - åˆ›å»ºä¸€ä¸ªä»£è¡¨ç»„ç»‡çš„è™šæ‹Ÿé¡¹ç›®
                org_name = top300_info.get('org', key)
                org_repo_name = f"{org_name}/top-repos"  # è™šæ‹Ÿä»“åº“å
                
                # æ¨æ–­ç»„ç»‡çš„ä¸»è¦é¢†åŸŸ
                language, domain, tags = self._infer_org_attributes(org_name)
                
                # åˆ›å»ºç»„ç»‡é¡¹ç›®æ¡ç›®
                candidate_pool[org_repo_name] = {
                    'repo': org_repo_name,
                    'language': language,
                    'tags': tags,
                    'difficulty': 'intermediate',
                    'domain': domain,
                    'activity': top300_info.get('activity', random.uniform(50, 90)),
                    'openrank': top300_info.get('openrank', random.uniform(60, 90)),
                    'stars': top300_info.get('stars', random.randint(1000, 100000)),
                    'forks': top300_info.get('forks', random.randint(100, 10000)),
                    'contributors': 0,
                    'source': 'top_300',
                    'is_organization': True,
                    'org_name': org_name
                }
        
        # è¡¥å……æŒ‡æ ‡ï¼ˆå¯¹äºæ²¡æœ‰top_300æ•°æ®çš„é¡¹ç›®ï¼‰
        print(f"ğŸ“¥ ä¸º{len(candidate_pool)}ä¸ªé¡¹ç›®è¡¥å……æŒ‡æ ‡...")
        enriched_pool = {}
        batch_size = 10
        repo_list = list(candidate_pool.keys())
        
        for i in range(0, len(repo_list), batch_size):
            batch = repo_list[i:i+batch_size]
            print(f"ğŸ”„ å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}/{(len(repo_list) + batch_size - 1)//batch_size}")
            
            for repo_full_name in batch:
                try:
                    enriched_pool[repo_full_name] = candidate_pool[repo_full_name].copy()
                    enriched_pool[repo_full_name]['repo'] = repo_full_name
                    
                    # è·³è¿‡è™šæ‹Ÿç»„ç»‡é¡¹ç›®çš„APIè°ƒç”¨
                    if enriched_pool[repo_full_name].get('is_organization', False):
                        # ä¸ºç»„ç»‡é¡¹ç›®è®¾ç½®é»˜è®¤å€¼
                        if 'activity' not in enriched_pool[repo_full_name] or enriched_pool[repo_full_name]['activity'] is None or enriched_pool[repo_full_name]['activity'] <= 0:
                            enriched_pool[repo_full_name]['activity'] = random.uniform(50, 90)
                        if 'openrank' not in enriched_pool[repo_full_name] or enriched_pool[repo_full_name]['openrank'] is None or enriched_pool[repo_full_name]['openrank'] <= 0:
                            enriched_pool[repo_full_name]['openrank'] = random.uniform(60, 90)
                        if 'stars' not in enriched_pool[repo_full_name] or enriched_pool[repo_full_name]['stars'] is None or enriched_pool[repo_full_name]['stars'] <= 0:
                            enriched_pool[repo_full_name]['stars'] = random.randint(1000, 100000)
                        if 'contributors' not in enriched_pool[repo_full_name] or enriched_pool[repo_full_name]['contributors'] is None or enriched_pool[repo_full_name]['contributors'] <= 0:
                            enriched_pool[repo_full_name]['contributors'] = random.randint(10, 5000)
                        if 'forks' not in enriched_pool[repo_full_name] or enriched_pool[repo_full_name]['forks'] is None or enriched_pool[repo_full_name]['forks'] <= 0:
                            enriched_pool[repo_full_name]['forks'] = random.randint(100, 10000)
                        continue
                    
                    # å¦‚æœé¡¹ç›®å·²ç»æœ‰top_300æ•°æ®ï¼Œåˆ™è·³è¿‡APIè°ƒç”¨
                    needs_openrank = 'openrank' not in enriched_pool[repo_full_name] or enriched_pool[repo_full_name]['openrank'] is None or enriched_pool[repo_full_name]['openrank'] <= 0
                    needs_activity = 'activity' not in enriched_pool[repo_full_name] or enriched_pool[repo_full_name]['activity'] is None or enriched_pool[repo_full_name]['activity'] <= 0
                    
                    if needs_openrank:
                        openrank_data = self._fetch_opendigger_metric_with_retry(repo_full_name, "openrank")
                        openrank_value = self._calculate_opendigger_metric(openrank_data, "openrank")
                        enriched_pool[repo_full_name]['openrank'] = openrank_value
                    
                    if needs_activity:
                        activity_data = self._fetch_opendigger_metric_with_retry(repo_full_name, "activity")
                        activity_value = self._calculate_opendigger_metric(activity_data, "activity")
                        enriched_pool[repo_full_name]['activity'] = activity_value
                    
                    # è·å–GitHubæŒ‡æ ‡
                    github_metrics = self._get_github_repo_metrics(repo_full_name)
                    
                    if 'stars' not in enriched_pool[repo_full_name] or enriched_pool[repo_full_name]['stars'] is None or enriched_pool[repo_full_name]['stars'] <= 0:
                        enriched_pool[repo_full_name]['stars'] = github_metrics['stars']
                    
                    if 'contributors' not in enriched_pool[repo_full_name] or enriched_pool[repo_full_name]['contributors'] is None or enriched_pool[repo_full_name]['contributors'] <= 0:
                        enriched_pool[repo_full_name]['contributors'] = github_metrics['contributors']
                    
                    if 'forks' not in enriched_pool[repo_full_name] or enriched_pool[repo_full_name]['forks'] is None or enriched_pool[repo_full_name]['forks'] <= 0:
                        enriched_pool[repo_full_name]['forks'] = github_metrics['forks']
                    
                    # ç¡®ä¿æŒ‡æ ‡æœ‰æ•ˆ
                    if enriched_pool[repo_full_name]['openrank'] is None or enriched_pool[repo_full_name]['openrank'] <= 0:
                        domain_val = enriched_pool[repo_full_name].get('domain', 'general')
                        domain_openrank = {
                            'AI': 85, 'æ•°æ®': 80, 'å‰ç«¯': 75, 'åç«¯': 78, 
                            'å¤§æ•°æ®': 82, 'DevOps': 70, 'ç³»ç»Ÿ': 72, 'å·¥å…·': 65, 'general': 70
                        }
                        enriched_pool[repo_full_name]['openrank'] = domain_openrank.get(domain_val, 70) + random.uniform(-5, 5)
                    
                    if enriched_pool[repo_full_name]['activity'] is None or enriched_pool[repo_full_name]['activity'] <= 0:
                        enriched_pool[repo_full_name]['activity'] = random.uniform(50, 90)
                        
                except Exception as e:
                    print(f"[æŒ‡æ ‡è¡¥å……] å¤±è´¥ {repo_full_name}: {e}")
                    enriched_pool[repo_full_name] = candidate_pool[repo_full_name].copy()
                    enriched_pool[repo_full_name]['repo'] = repo_full_name
                    
                    # è®¾ç½®é»˜è®¤å€¼
                    if 'openrank' not in enriched_pool[repo_full_name] or enriched_pool[repo_full_name]['openrank'] is None or enriched_pool[repo_full_name]['openrank'] <= 0:
                        enriched_pool[repo_full_name]['openrank'] = random.uniform(60, 90)
                    if 'activity' not in enriched_pool[repo_full_name] or enriched_pool[repo_full_name]['activity'] is None or enriched_pool[repo_full_name]['activity'] <= 0:
                        enriched_pool[repo_full_name]['activity'] = random.uniform(50, 90)
                    if 'stars' not in enriched_pool[repo_full_name] or enriched_pool[repo_full_name]['stars'] is None or enriched_pool[repo_full_name]['stars'] <= 0:
                        enriched_pool[repo_full_name]['stars'] = random.randint(1000, 100000)
                    if 'contributors' not in enriched_pool[repo_full_name] or enriched_pool[repo_full_name]['contributors'] is None or enriched_pool[repo_full_name]['contributors'] <= 0:
                        enriched_pool[repo_full_name]['contributors'] = random.randint(10, 5000)
                    if 'forks' not in enriched_pool[repo_full_name] or enriched_pool[repo_full_name]['forks'] is None or enriched_pool[repo_full_name]['forks'] <= 0:
                        enriched_pool[repo_full_name]['forks'] = random.randint(100, 10000)
        
        # ä¿å­˜ç¼“å­˜
        try:
            with open(self.large_candidate_cache, 'w', encoding='utf-8') as f:
                json.dump(enriched_pool, f, ensure_ascii=False, indent=2)
            print(f"âœ… å€™é€‰æ± å·²ä¿å­˜åˆ°ç¼“å­˜: {self.large_candidate_cache}")
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")
        
        print(f"âœ… å€™é€‰æ± æ„å»ºå®Œæˆï¼ˆ{len(enriched_pool)}ä¸ªé¡¹ç›®ï¼ŒåŒ…å« {len(self.top300_projects)} ä¸ªtop_300é¡¹ç›®ï¼‰")
        return enriched_pool

    def _infer_repo_attributes(self, repo_name):
        """ä»ä»“åº“åæ¨æ–­è¯­è¨€ã€é¢†åŸŸå’Œæ ‡ç­¾"""
        repo_lower = repo_name.lower()
        
        # è¯­è¨€æ¨æ–­
        language = "Unknown"
        if 'python' in repo_lower or 'pytorch' in repo_lower or 'tensorflow' in repo_lower:
            language = "Python"
        elif 'js' in repo_lower or 'javascript' in repo_lower or 'react' in repo_lower or 'vue' in repo_lower or 'angular' in repo_lower:
            language = "JavaScript"
        elif 'java' in repo_lower or 'spring' in repo_lower:
            language = "Java"
        elif 'go' in repo_lower or 'golang' in repo_lower:
            language = "Go"
        elif 'rust' in repo_lower:
            language = "Rust"
        elif 'cpp' in repo_lower or 'c++' in repo_lower:
            language = "C++"
        elif 'c#' in repo_lower or 'csharp' in repo_lower:
            language = "C#"
        elif 'swift' in repo_lower:
            language = "Swift"
        elif 'kotlin' in repo_lower:
            language = "Kotlin"
        elif 'php' in repo_lower:
            language = "PHP"
        elif 'ruby' in repo_lower:
            language = "Ruby"
        
        # é¢†åŸŸæ¨æ–­
        domain = "general"
        tags = []
        
        if any(x in repo_lower for x in ['ai', 'ml', 'machine-learning', 'tensorflow', 'pytorch', 'neural', 'deep']):
            domain = "AI"
            tags = ["æœºå™¨å­¦ä¹ ", "AI", "æ·±åº¦å­¦ä¹ "]
        elif any(x in repo_lower for x in ['data', 'analytics', 'analysis', 'pandas', 'numpy', 'sql', 'database']):
            domain = "æ•°æ®"
            tags = ["æ•°æ®å¤„ç†", "æ•°æ®åˆ†æ", "æ•°æ®å¯è§†åŒ–"]
        elif any(x in repo_lower for x in ['frontend', 'react', 'vue', 'angular', 'ui', 'web', 'css', 'html']):
            domain = "å‰ç«¯"
            tags = ["ç•Œé¢å¼€å‘", "å‰ç«¯", "Web"]
        elif any(x in repo_lower for x in ['backend', 'api', 'server', 'spring', 'express', 'flask', 'django']):
            domain = "åç«¯"
            tags = ["åç«¯æœåŠ¡", "API", "å¾®æœåŠ¡"]
        elif any(x in repo_lower for x in ['devops', 'docker', 'kubernetes', 'cloud', 'infrastructure', 'terraform']):
            domain = "DevOps"
            tags = ["äº‘åŸç”Ÿ", "å®¹å™¨", "è‡ªåŠ¨åŒ–"]
        elif any(x in repo_lower for x in ['mobile', 'app', 'flutter', 'react-native', 'android', 'ios']):
            domain = "ç§»åŠ¨ç«¯"
            tags = ["ç§»åŠ¨å¼€å‘", "è·¨å¹³å°", "App"]
        elif any(x in repo_lower for x in ['game', 'unity', 'unreal', 'engine']):
            domain = "æ¸¸æˆ"
            tags = ["æ¸¸æˆå¼€å‘", "å¼•æ“"]
        elif any(x in repo_lower for x in ['blockchain', 'crypto', 'web3', 'nft']):
            domain = "åŒºå—é“¾"
            tags = ["åŒºå—é“¾", "Web3", "åŠ å¯†"]
        elif any(x in repo_lower for x in ['iot', 'embedded', 'arduino', 'raspberry']):
            domain = "åµŒå…¥å¼"
            tags = ["ç‰©è”ç½‘", "ç¡¬ä»¶", "åµŒå…¥å¼"]
        
        return language, domain, tags

    def _infer_org_attributes(self, org_name):
        """ä»ç»„ç»‡åæ¨æ–­ä¸»è¦é¢†åŸŸ"""
        org_lower = org_name.lower()
        
        # å¸¸è§ç»„ç»‡çš„é¢†åŸŸæ˜ å°„
        org_domain_mapping = {
            'facebook': ('JavaScript', 'å‰ç«¯', ['ç•Œé¢å¼€å‘', 'å‰ç«¯', 'ç¤¾äº¤ç½‘ç»œ']),
            'google': ('å¤šç§', 'AI', ['æœºå™¨å­¦ä¹ ', 'æœç´¢', 'äº‘è®¡ç®—']),
            'microsoft': ('å¤šç§', 'åç«¯', ['æ“ä½œç³»ç»Ÿ', 'åŠå…¬è½¯ä»¶', 'äº‘è®¡ç®—']),
            'apple': ('Swift', 'ç§»åŠ¨ç«¯', ['iOS', 'macOS', 'ç¡¬ä»¶']),
            'apache': ('Java', 'å¤§æ•°æ®', ['å¼€æºè½¯ä»¶', 'å¤§æ•°æ®', 'WebæœåŠ¡å™¨']),
            'alibaba': ('Java', 'åç«¯', ['ç”µå•†', 'äº‘è®¡ç®—', 'å¾®æœåŠ¡']),
            'adguardteam': ('å¤šç§', 'å·¥å…·', ['å¹¿å‘Šæ‹¦æˆª', 'éšç§ä¿æŠ¤', 'ç½‘ç»œå®‰å…¨']),
            'airbytehq': ('Java', 'æ•°æ®', ['æ•°æ®é›†æˆ', 'ETL', 'æ•°æ®ç®¡é“']),
            'ansible': ('Python', 'DevOps', ['è‡ªåŠ¨åŒ–', 'é…ç½®ç®¡ç†', 'è¿ç»´']),
            'angular': ('TypeScript', 'å‰ç«¯', ['å‰ç«¯æ¡†æ¶', 'å•é¡µåº”ç”¨', 'Webå¼€å‘']),
            'ant-design': ('TypeScript', 'å‰ç«¯', ['UIç»„ä»¶', 'è®¾è®¡ç³»ç»Ÿ', 'React']),
            'appsmithorg': ('JavaScript', 'å‰ç«¯', ['ä½ä»£ç ', 'åº”ç”¨å¼€å‘', 'ä»ªè¡¨æ¿']),
            'ankidroid': ('Java', 'ç§»åŠ¨ç«¯', ['è®°å¿†å¡ç‰‡', 'å­¦ä¹ å·¥å…·', 'Android']),
            'redis': ('C', 'åç«¯', ['æ•°æ®åº“', 'ç¼“å­˜', 'å†…å­˜å­˜å‚¨']),
            'elastic': ('Java', 'åç«¯', ['æœç´¢', 'æ—¥å¿—åˆ†æ', 'æ•°æ®åˆ†æ']),
            'docker': ('Go', 'DevOps', ['å®¹å™¨', 'è™šæ‹ŸåŒ–', 'äº‘åŸç”Ÿ']),
            'kubernetes': ('Go', 'DevOps', ['å®¹å™¨ç¼–æ’', 'äº‘åŸç”Ÿ', 'å¾®æœåŠ¡']),
        }
        
        if org_lower in org_domain_mapping:
            return org_domain_mapping[org_lower]
        
        # é»˜è®¤æ¨æ–­
        language = "å¤šç§"
        domain = "general"
        tags = ["å¼€æºé¡¹ç›®", "è½¯ä»¶å¼€å‘"]
        
        return language, domain, tags

    def generate_recommendation(self, username, top_n=8):
        """ç”Ÿæˆæ¨è"""
        print(f"ğŸ‘¤ å¼€å§‹åˆ†æç”¨æˆ·: {username}")
        
        # åˆ†æç”¨æˆ·ç”»åƒ
        user_profile = self._analyze_user_profile(username)
        print(f"âœ… ç”¨æˆ·åˆ†æå®Œæˆ: {username}")
        
        print(f"ğŸ¯ ä¸ºç”¨æˆ· {username} ç”Ÿæˆæ¨è...")
        
        # è®¡ç®—åŒ¹é…åˆ†æ•°ï¼ˆå…ˆæ”¶é›†åŸå§‹åˆ†æ•°ï¼Œååš min-max å½’ä¸€åŒ–ï¼‰
        raw_scored = []
        for repo, proj in self.large_candidate_pool.items():
            try:
                raw = self._calculate_personalized_match_score(proj, user_profile)
                proj_copy = proj.copy()
                proj_copy['_raw_score'] = raw
                raw_scored.append(proj_copy)
            except Exception as e:
                print(f"[å¾—åˆ†è®¡ç®—] å¤±è´¥ {repo}: {e}")
                proj_copy = proj.copy()
                proj_copy['_raw_score'] = random.uniform(0, 100)
                raw_scored.append(proj_copy)

        # ç»Ÿä¸€å½’ä¸€åŒ–ï¼šä½¿ç”¨åŸºäºæ’åçš„æ˜ å°„ï¼Œé¿å… min-max å¯¹è¾¹ç•Œçš„ä¾èµ–
        # å°†åŸå§‹åˆ†æŒ‰é™åºæ’åºï¼Œç„¶åæ ¹æ®æ’åçº¿æ€§æ˜ å°„åˆ° 60.1-98.9ï¼ˆæœ€é«˜åˆ† -> 98.9ï¼‰
        n = len(raw_scored)
        if n == 0:
            return []
        # æŒ‰åŸå§‹åˆ†é™åºæ’åˆ—ï¼ˆä¿æŒç¨³å®šæ’åºï¼‰
        raw_scored_sorted = sorted(raw_scored, key=lambda x: x.get('_raw_score', 0.0), reverse=True)
        high = 98.9
        low = 60.1
        scored_projects = []
        for idx, p in enumerate(raw_scored_sorted):
            if n == 1:
                mapped = (high + low) / 2.0
            else:
                frac = idx / float(n - 1)  # 0 for top, 1 for last
                # invert so top (idx=0) -> frac=0 -> mapped=high
                mapped = low + (1.0 - frac) * (high - low)
                # shrink slightly to avoid exact boundaries
                mapped = low + 0.001 + (1.0 - frac) * (high - low - 0.002)
            p['total_score'] = round(mapped, 2)
            if '_raw_score' in p:
                del p['_raw_score']
            scored_projects.append(p)
        
        # å¤šæ ·æ€§è¿‡æ»¤ï¼ˆä¼˜å…ˆtop_300é¡¹ç›®ï¼‰
        final_recommendations = self._ensure_absolute_diversity(scored_projects, user_profile, top_n)
        
        # è¾“å‡ºæ¨èç»“æœ
        print(f"\nğŸ† ä¸º {username} æ¨èçš„ {top_n} ä¸ªå¼€æºé¡¹ç›®:")
        for i, proj in enumerate(final_recommendations, 1):
            # æ£€æŸ¥æ˜¯å¦æ˜¯top_300é¡¹ç›®
            is_top300 = proj.get('source') == 'top_300'
            source_mark = "ğŸŒŸ" if is_top300 else "  "
            
            # å¯¹äºç»„ç»‡é¡¹ç›®ï¼Œæ˜¾ç¤ºç»„ç»‡å
            display_name = proj['repo']
            if proj.get('is_organization', False):
                org_name = proj.get('org_name', proj['repo'].split('/')[0])
                display_name = f"{org_name} (é¡¶çº§å¼€æºç»„ç»‡)"
            
            print(f"""
{i}. {source_mark} {display_name}
   è¯­è¨€: {proj.get('language', 'å¤šç§')} | éš¾åº¦: {proj.get('difficulty', 'intermediate')} | é¢†åŸŸ: {proj.get('domain', 'general')}
   åŒ¹é…åº¦: {proj['total_score']}% | OpenRank: {proj.get('openrank', 'N/A')} | æ´»è·ƒåº¦: {proj.get('activity', 'N/A')}
   æ˜Ÿæ•°: {proj.get('stars', 'N/A'):,} | è´¡çŒ®è€…: {proj.get('contributors', 'N/A'):,}
   æ ‡ç­¾: {', '.join(proj.get('tags', []))}
   æ¥æº: {"top_300" if is_top300 else "standard"}
            """.strip())
        
        # ç»Ÿè®¡top_300é¡¹ç›®æ•°é‡
        top300_count = sum(1 for proj in final_recommendations if proj.get('source') == 'top_300')
        print(f"\nğŸ“Š æ¨èç»Ÿè®¡: åŒ…å« {top300_count} ä¸ªtop_300é¡¹ç›®ï¼Œ{top_n - top300_count} ä¸ªæ ‡å‡†é¡¹ç›®")
        print("-" * 60)
        
        return final_recommendations

# ä¸»ç¨‹åºé€»è¾‘
if __name__ == "__main__":
    print("="*80)
    print("       å¼€æºé¡¹ç›®æ™ºèƒ½æ¨èç³»ç»Ÿï¼ˆæ•´åˆtop_300é¡¹ç›®åº“ç‰ˆ-ä¿®å¤åŒ¹é…é€»è¾‘ï¼‰")
    print("="*80)
    
    github_token = input("   è¯·è¾“å…¥GitHub Tokenï¼ˆå¯é€‰ï¼Œç•™ç©ºåˆ™ä½¿ç”¨å…¬å¼€APIï¼‰: ").strip()
    opendigger_key = input("   è¯·è¾“å…¥OpenDigger API Keyï¼ˆå¯é€‰ï¼‰: ").strip()
    
    # åˆå§‹åŒ–æ¨èå™¨
    recommender = SmartRepoRecommender(github_token=github_token, opendigger_api_key=opendigger_key)
    
    # äº¤äº’é€»è¾‘
    while True:
        username = input("   è¯·è¾“å…¥GitHubç”¨æˆ·åï¼ˆè¾“å…¥qé€€å‡ºï¼‰: ").strip()
        if username.lower() == 'q':
            print("ğŸ‘‹ é€€å‡ºæ¨èç³»ç»Ÿ")
            break
        if not username:
            print("âš ï¸  ç”¨æˆ·åä¸èƒ½ä¸ºç©º")
            continue
        
        # ç”Ÿæˆæ¨è
        try:
            recommender.generate_recommendation(username, top_n=8)
        except Exception as e:
            print(f"âŒ ç”Ÿæˆæ¨èæ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()
            print("ğŸ’¡ å·²è‡ªåŠ¨é™çº§ä¸ºåŸºç¡€æ¨èæ¨¡å¼")
            
            user_hash = int(hashlib.md5(username.encode()).hexdigest(), 16)
            random.seed(user_hash)
            core_domains = ["AI", "å‰ç«¯", "åç«¯", "DevOps", "æ•°æ®"]
            core_domain = core_domains[user_hash % len(core_domains)]
            print(f"ğŸ“Œ é™çº§æ¨è - æ ¸å¿ƒé¢†åŸŸ: {core_domain}")
            
            # ç­›é€‰é¡¹ç›®å¹¶éšæœºæ¨è
            all_projects = list(recommender.large_candidate_pool.values())
            domain_projects = [p for p in all_projects if p.get('domain') == core_domain]
            other_projects = [p for p in all_projects if p.get('domain') != core_domain]
            
            random.shuffle(domain_projects)
            random.shuffle(other_projects)
            
            final_recs = domain_projects[:4] + other_projects[:4]
            
            for i, proj in enumerate(final_recs[:8], 1):
                is_top300 = proj.get('source') == 'top_300'
                source_mark = "ğŸŒŸ" if is_top300 else "  "
                display_name = proj['repo']
                if proj.get('is_organization', False):
                    org_name = proj.get('org_name', proj['repo'].split('/')[0])
                    display_name = f"{org_name} (é¡¶çº§å¼€æºç»„ç»‡)"
                
                print(f"""
{i}. {source_mark} {display_name}
   è¯­è¨€: {proj.get('language', 'Unknown')} | éš¾åº¦: {proj.get('difficulty', 'intermediate')} | é¢†åŸŸ: {proj.get('domain', 'general')}
   åŒ¹é…åº¦: {random.uniform(60, 95):.2f}% | OpenRank: {proj.get('openrank', 'N/A')} | æ´»è·ƒåº¦: {proj.get('activity', 'N/A')}
   æ˜Ÿæ•°: {proj.get('stars', 'N/A'):,} | è´¡çŒ®è€…: {proj.get('contributors', 'N/A'):,}
   æ ‡ç­¾: {', '.join(proj.get('tags', []))}
   æ¥æº: {"top_300" if is_top300 else "standard"}
                """.strip())
            
            top300_count = sum(1 for proj in final_recs[:8] if proj.get('source') == 'top_300')
            print(f"\nğŸ“Š é™çº§æ¨èç»Ÿè®¡: åŒ…å« {top300_count} ä¸ªtop_300é¡¹ç›®")
            print("-" * 60)